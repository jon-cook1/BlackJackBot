{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning:\n",
    "    # learn_r -> learning rate      exp_r -> experimenting rate (how often to randomly choose)\n",
    "    def __init__(self, learn_r=0.1, exp_r=0.3):  \n",
    "\n",
    "        self.player_Q_Values = {}  \n",
    "        \n",
    "        # key: [(player_val, up_card, ace)][action] = value\n",
    "        # initialise Q values | (12-21) x (1-10) x (True, False) x (1, 0) 400 in total\n",
    "            # This essentially represents each possible action in the game. Each combination of\n",
    "                # player sum (hard and soft)/ dealer up card with 1 and 0 to represent the choice for that combination\n",
    "        \n",
    "        for i in range(12, 22):\n",
    "            for j in range(1, 11):\n",
    "                for k in [True, False]:\n",
    "                    self.player_Q_Values[(i, j, k)] = {}\n",
    "                    for a in [1, 0]:\n",
    "                        if i == 21 and a == 0:\n",
    "                            self.player_Q_Values[(i, j, k)][a] = 1\n",
    "                        else:\n",
    "                            self.player_Q_Values[(i, j, k)][a] = 0\n",
    "        \n",
    "        \n",
    "        self.state = (0, 0, False)  # default state\n",
    "        self.actions = [1, 0]  # 1 -> hit, 0 -> stand\n",
    "        self.player_state_action = []\n",
    "        self.end = False\n",
    "        self.learn_r = learn_r\n",
    "        self.exp_r = exp_r\n",
    "\n",
    "    # Same logic here as in MC\n",
    "    @staticmethod\n",
    "    def giveCard():\n",
    "        cards = [1,2,3,4,5,6,7,8,9,10,10,10,10]\n",
    "        return np.random.choice(cards)\n",
    "    \n",
    "    # Used to allow auto win if 21 is pulled off deal\n",
    "    def deal2cards(self, show=False):\n",
    "        cards = [self.giveCard(), self.giveCard()]\n",
    "        \n",
    "        val = sum(cards)\n",
    "        if 1 in cards:\n",
    "            val += 10\n",
    "            ace = True\n",
    "        else:\n",
    "            ace = False\n",
    "\n",
    "        if show:\n",
    "            return val, ace, cards[0]\n",
    "        else:\n",
    "            return val, ace\n",
    "    \n",
    "    def dealerLogic(self, val, ace):\n",
    "        if val > 21:\n",
    "            if ace:\n",
    "                val -= 10\n",
    "                ace = False\n",
    "            else:\n",
    "                return val, ace, True    \n",
    "\n",
    "        # Assuming dealer stands on hard, hits soft 17, can be changed later\n",
    "        if val > 17 or (val == 17 and not ace):\n",
    "            return val, ace, True\n",
    "        \n",
    "        card = self.giveCard()\n",
    "        if card == 1:\n",
    "            if val + 11 > 21:\n",
    "                # Card must be hard ace (1)\n",
    "                return val + 1, ace, False\n",
    "            else:\n",
    "                # Card can be a soft ace (11)\n",
    "                return val + 11, True, False\n",
    "        else:\n",
    "            return val+card, ace, False\n",
    "    \n",
    "\n",
    "    def chooseAction(self):\n",
    "        # Always hit if val <= 11. Can change for testing\n",
    "        print(\"Here:\", self.state)\n",
    "        current_val = self.state[0]\n",
    "        if current_val <= 11:\n",
    "            return 1\n",
    "        \n",
    "        # Here we balance experimentation vs explotiation\n",
    "            # This means exp_r precent of the time, hit or stay is chosen at random\n",
    "                # Otherwise, we rely on action that gains the besr reward\n",
    "        \n",
    "        # 'Decide' if a random choice will be made \n",
    "        if np.random.uniform(0, 1) <= self.exp_r:\n",
    "            decision = np.random.choice(self.actions)\n",
    "        else:\n",
    "            # Greedy action\n",
    "            v = float('-inf')\n",
    "            decision = 0\n",
    "            for a in self.player_Q_Values[self.state]:\n",
    "                if self.player_Q_Values[self.state][a] > v:\n",
    "                    decision = a\n",
    "                    v = self.player_Q_Values[self.state][a]\n",
    "        return decision\n",
    "\n",
    "    # Take in action, update to next state, and determine if game is over\n",
    "    def playerNxtState(self, action):\n",
    "            print(\"Action:\",action)\n",
    "            current_val, up_card, ace = self.state      #unpack tuple\n",
    "            \n",
    "            if action:\n",
    "                card = self.giveCard()\n",
    "                if card == 1:\n",
    "                    if current_val <= 10:\n",
    "                        current_val += 11\n",
    "                        ace = True\n",
    "                    else:\n",
    "                        current_val += 1\n",
    "                else:\n",
    "                    current_val += card\n",
    "            else:\n",
    "                # Player stands\n",
    "                self.end = True\n",
    "            \n",
    "            if current_val > 21:\n",
    "                if ace:\n",
    "                    current_val -= 10\n",
    "                    ace = False\n",
    "                else:\n",
    "                    self.end = True\n",
    "            self.state = (current_val, up_card, ace)\n",
    "\n",
    "        \n",
    "    def reward(self, player_val, dealer_val, end=True):\n",
    "        reward = 0\n",
    "        if end:\n",
    "            if player_val > 21:\n",
    "                reward = -1\n",
    "            else:\n",
    "                if dealer_val > 21 or player_val > dealer_val:\n",
    "                    reward = 1\n",
    "                else:\n",
    "                    reward = -1 if player_val < dealer_val else 0\n",
    "\n",
    "        # Backpropagate the determined reward\n",
    "        # Called a Q-value update gradient descent\n",
    "        for s in reversed(self.player_state_action):\n",
    "            state, action = s\n",
    "            reward = self.learn_r * (reward - self.player_Q_Values[state][action]) + self.player_Q_Values[state][action]\n",
    "            self.player_Q_Values[state][action] = round(reward, 3)\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.player_state_action = []\n",
    "        self.state = (0, 0, False)  # initial state\n",
    "        self.end = False\n",
    "\n",
    "\n",
    "    def play(self, rounds=1000):\n",
    "        for round in range(rounds):\n",
    "            if round % 1000 == 0:  # Check every 1000 rounds\n",
    "                print(f\"Round: {round}\")\n",
    "\n",
    "            # Deal\n",
    "            dealer_val, d_ace, up_card = self.deal2cards(show=True)\n",
    "            player_val, p_ace = self.deal2cards(show=False)\n",
    "\n",
    "            self.state = (player_val, up_card, p_ace)\n",
    "            print(\"init\", self.state)\n",
    "\n",
    "            if player_val != 21 and dealer_val != 21:\n",
    "                while not self.end:\n",
    "                    action = self.chooseAction() \n",
    "                    if self.state[0] >= 12:\n",
    "                        state_action_pair = [self.state, action]\n",
    "                        self.player_state_action.append(state_action_pair)\n",
    "                    self.playerNxtState(action)\n",
    "\n",
    "                # Dealer plays\n",
    "                end = False\n",
    "                while not end:\n",
    "                    dealer_val, d_ace, end = self.dealerLogic(dealer_val, d_ace)\n",
    "\n",
    "                # Give reward and update Q value\n",
    "                player_val = self.state[0]\n",
    "                print(\"player value {} | dealer value {}\".format(player_val, dealer_val))\n",
    "                self.reward(player_val, dealer_val)\n",
    "\n",
    "            self.reset()\n",
    "\n",
    "    def saveStrategy(self, file=\"strategy\"):\n",
    "        fw = open(file, 'wb')\n",
    "        pickle.dump(self.player_Q_Values, fw)\n",
    "        fw.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot = Qlearning()\n",
    "bot.play(100000)\n",
    "print(\"Training Complete\")\n",
    "bot.saveStrategy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bjbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
